{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setAnalisisArea(w,h):\n",
    "    streamWIDTH  = stream.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    streamHEIGHT = stream.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "#    streamWIDTH  = 500\n",
    "#    streamHEIGHT = 480\n",
    "\n",
    "    # Define an initial bounding box\n",
    "#    bbox = (287, 230, 860, 320)\n",
    "    abox = (int(w),int(h))\n",
    "    bbox = (streamWIDTH/2-abox[0]/2, streamHEIGHT*2/3-abox[1]/2,abox[0], abox[1])\n",
    "#    bbox = (streamWIDTH/2-abox[0]/2, streamHEIGHT*1/3-abox[1]/2,abox[0], abox[1])\n",
    "    \n",
    "    # Draw bounding box\n",
    "    p1 = (int(bbox[0]), int(bbox[1]))\n",
    "    p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "    return p1,p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawInfoBox(frame,p1,p2,text):\n",
    "    \n",
    "    # Check screen parameters\n",
    "    streamFPS = stream.get(cv2.CAP_PROP_FPS)\n",
    "    streamWIDTH  = stream.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    streamHEIGHT = stream.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "    # Draw bounding box\n",
    "    cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "\n",
    "\n",
    "    # Display text on frame\n",
    "    cv2.putText(frame,\"Info: \", (p2[0]+10,p1[1] - 10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255,0,0),2);  \n",
    "    cv2.putText(frame,\"FPS:    \"+str(streamFPS), (p2[0]+10,p1[1] + 15), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255,0,0),2);  \n",
    "    cv2.putText(frame,\"Width:  \"+str(streamWIDTH), (p2[0]+10,p1[1] + 40), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255,0,0),2);  \n",
    "    cv2.putText(frame,\"Height: \"+str(streamHEIGHT), (p2[0]+10,p1[1] + 65), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255,0,0),2);  \n",
    "    cv2.putText(frame,\"Text: \"+ text, (p2[0]+10,p1[1] + 90), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,255),2);  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractText(frame):\n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # define range of blue color in HSV\n",
    "#    lower_blue = np.array([110,50,50])\n",
    "#    upper_blue = np.array([130,255,255])\n",
    "    \n",
    "    # define range of white color in HSV\n",
    "#    lower_white = np.array([0,0,0], dtype=np.uint8)\n",
    "#    upper_white = np.array([0,0,255], dtype=np.uint8)\n",
    "\n",
    "    # Threshold the HSV image to get only blue colors\n",
    "#    mask = cv2.inRange(hsv, lower_white, upper_white)\n",
    "\n",
    "    # Red lower mask (0-10)\n",
    "    lower_red = np.array([0,70,50])\n",
    "#    lower_red = np.array([0,50,50])\n",
    "    upper_red = np.array([10,255,255])\n",
    "    mask_r0 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "    # Red upper mask (170-180)\n",
    "    lower_red = np.array([170,70,50])\n",
    "#    lower_red = np.array([170,50,50])\n",
    "    upper_red = np.array([180,255,255])\n",
    "    mask_r1 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "\n",
    "    # define range of white color in HSV\n",
    "    lower_white = np.array([0,0,230])\n",
    "    upper_white = np.array([180,20,255])\n",
    "    mask_w = cv2.inRange(hsv, lower_white, upper_white)\n",
    "\n",
    "    # join my masks\n",
    "#    mask_2 = cv2.inRange(frame, (low_H, low_S, low_V), (high_H, high_S, high_V))\n",
    "    \n",
    "#    mask = mask +mask0+mask1\n",
    "#    mask = mask + mask1\n",
    "#    mask = cv2.bitwise_xor(mask1, mask)\n",
    "#    mask = mask_r0|mask_r1|mask_w\n",
    "    mask = mask_w\n",
    "\n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "#    res =  mask\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_name = \"Crop\"\n",
    "max_value = 255\n",
    "max_value_H = 360//2\n",
    "low_H = 0\n",
    "low_S = 0\n",
    "low_V = 0\n",
    "high_H = max_value_H\n",
    "high_S = max_value\n",
    "high_V = max_value\n",
    "\n",
    "low_H_name = 'Low H'\n",
    "low_S_name = 'Low S'\n",
    "low_V_name = 'Low V'\n",
    "high_H_name = 'High H'\n",
    "high_S_name = 'High S'\n",
    "high_V_name = 'High V'\n",
    "\n",
    "def on_low_H_thresh_trackbar(val):\n",
    "    global low_H\n",
    "    global high_H\n",
    "    low_H = val\n",
    "    low_H = min(high_H-1, low_H)\n",
    "    cv2.setTrackbarPos(low_H_name, window_name, low_H)\n",
    "def on_high_H_thresh_trackbar(val):\n",
    "    global low_H\n",
    "    global high_H\n",
    "    high_H = val\n",
    "    high_H = max(high_H, low_H+1)\n",
    "    cv2.setTrackbarPos(high_H_name, window_name, high_H)\n",
    "def on_low_S_thresh_trackbar(val):\n",
    "    global low_S\n",
    "    global high_S\n",
    "    low_S = val\n",
    "    low_S = min(high_S-1, low_S)\n",
    "    cv2.setTrackbarPos(low_S_name, window_name, low_S)\n",
    "def on_high_S_thresh_trackbar(val):\n",
    "    global low_S\n",
    "    global high_S\n",
    "    high_S = val\n",
    "    high_S = max(high_S, low_S+1)\n",
    "    cv2.setTrackbarPos(high_S_name, window_name, high_S)\n",
    "def on_low_V_thresh_trackbar(val):\n",
    "    global low_V\n",
    "    global high_V\n",
    "    low_V = val\n",
    "    low_V = min(high_V-1, low_V)\n",
    "    cv2.setTrackbarPos(low_V_name, window_name, low_V)\n",
    "def on_high_V_thresh_trackbar(val):\n",
    "    global low_V\n",
    "    global high_V\n",
    "    high_V = val\n",
    "    high_V = max(high_V, low_V+1)\n",
    "    cv2.setTrackbarPos(high_V_name, window_name, high_V)\n",
    "    \n",
    "def createTrackBar(window_name):\n",
    "    cv2.createTrackbar(low_H_name, window_name , low_H, max_value_H, on_low_H_thresh_trackbar)\n",
    "    cv2.createTrackbar(high_H_name, window_name , high_H, max_value_H, on_high_H_thresh_trackbar)\n",
    "    cv2.createTrackbar(low_S_name, window_name , low_S, max_value, on_low_S_thresh_trackbar)\n",
    "    cv2.createTrackbar(high_S_name, window_name , high_S, max_value, on_high_S_thresh_trackbar)\n",
    "    cv2.createTrackbar(low_V_name, window_name , low_V, max_value, on_low_V_thresh_trackbar)\n",
    "    cv2.createTrackbar(high_V_name, window_name , high_V, max_value, on_high_V_thresh_trackbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_URL = \"https://bl.webcaster.pro/media/playlist/free_361ac6c7ea479629f777e6fab966ead2_hd/381_81890575/1080p/74bd89dc811014cb7e81b42b51074713/4682340436.m3u8\"\n",
    "\n",
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "stream = cv2.VideoCapture(VIDEO_URL)\n",
    "\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (stream.isOpened()== False): \n",
    "    print(\"Error opening video stream or file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd ='C:\\\\Program Files (x86)\\\\Tesseract-OCR\\\\tesseract'\n",
    "tessdata_dir_config = '--tessdata-dir \"C:\\\\Program Files (x86)\\\\Tesseract-OCR\\\\tessdata\"'\n",
    "\n",
    "w,h = 480,240\n",
    "# Read until video is completed\n",
    "while(stream.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = stream.read()\n",
    "    if ret == True:\n",
    "        p1,p2 = setAnalisisArea(w,h)\n",
    "        \n",
    "        crop_img = frame[p1[1]:p2[1],p1[0]:p2[0]]\n",
    "        \n",
    "        img = extractText(crop_img)\n",
    "\n",
    "#        cv2.imshow('Crop',img)        \n",
    "#        createTrackBar('Crop')\n",
    "        # Convert it into grayscale and display again\n",
    "        bgr = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    \n",
    "        cv2.imshow('Crop',gray)        \n",
    "        \n",
    "        # Smooth the image to get more accurate results\n",
    "        # Define the kernel size for gaussian smoothing\n",
    "#        kernel_size = 5\n",
    "#        blur_gray = cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "#        cv2.imshow('Crop', blur_gray) \n",
    "\n",
    "#        filename = \"{}.png\".format(os.getpid())\n",
    "#        cv2.imwrite(filename, gray)\n",
    "#        text = pytesseract.image_to_string(Image.open(filename))\n",
    "#        os.remove(filename)\n",
    "        \n",
    "        # OR explicit beforehand converting\n",
    "        text = pytesseract.image_to_string(Image.fromarray(gray))\n",
    "#        print(pytesseract.image_to_string(Image.fromarray(gray))\n",
    "#        print(text)\n",
    "#        low_threshold = 100\n",
    "#        high_threshold = 200\n",
    "#        edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "#        cv2.imshow('Crop', edges) \n",
    "\n",
    "        drawInfoBox(frame,p1,p2,text)    \n",
    "        cv2.imshow('Frame',frame)\n",
    "        \n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    " \n",
    "    # Break the loop\n",
    "    else: \n",
    "            break\n",
    "\n",
    "# When everything done, release the video capture object\n",
    "stream.release()\n",
    " \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2 as cv\n",
    "import argparse\n",
    "max_value = 255\n",
    "max_value_H = 360//2\n",
    "low_H = 0\n",
    "low_S = 0\n",
    "low_V = 0\n",
    "high_H = max_value_H\n",
    "high_S = max_value\n",
    "high_V = max_value\n",
    "window_capture_name = 'Video Capture'\n",
    "window_detection_name = 'Object Detection'\n",
    "low_H_name = 'Low H'\n",
    "low_S_name = 'Low S'\n",
    "low_V_name = 'Low V'\n",
    "high_H_name = 'High H'\n",
    "high_S_name = 'High S'\n",
    "high_V_name = 'High V'\n",
    "\n",
    "def on_low_H_thresh_trackbar(val):\n",
    "    global low_H\n",
    "    global high_H\n",
    "    low_H = val\n",
    "    low_H = min(high_H-1, low_H)\n",
    "    cv.setTrackbarPos(low_H_name, window_detection_name, low_H)\n",
    "def on_high_H_thresh_trackbar(val):\n",
    "    global low_H\n",
    "    global high_H\n",
    "    high_H = val\n",
    "    high_H = max(high_H, low_H+1)\n",
    "    cv.setTrackbarPos(high_H_name, window_detection_name, high_H)\n",
    "def on_low_S_thresh_trackbar(val):\n",
    "    global low_S\n",
    "    global high_S\n",
    "    low_S = val\n",
    "    low_S = min(high_S-1, low_S)\n",
    "    cv.setTrackbarPos(low_S_name, window_detection_name, low_S)\n",
    "def on_high_S_thresh_trackbar(val):\n",
    "    global low_S\n",
    "    global high_S\n",
    "    high_S = val\n",
    "    high_S = max(high_S, low_S+1)\n",
    "    cv.setTrackbarPos(high_S_name, window_detection_name, high_S)\n",
    "def on_low_V_thresh_trackbar(val):\n",
    "    global low_V\n",
    "    global high_V\n",
    "    low_V = val\n",
    "    low_V = min(high_V-1, low_V)\n",
    "    cv.setTrackbarPos(low_V_name, window_detection_name, low_V)\n",
    "def on_high_V_thresh_trackbar(val):\n",
    "    global low_V\n",
    "    global high_V\n",
    "    high_V = val\n",
    "    high_V = max(high_V, low_V+1)\n",
    "    cv.setTrackbarPos(high_V_name, window_detection_name, high_V)\n",
    "\n",
    "#parser = argparse.ArgumentParser(description='Code for Thresholding Operations using inRange tutorial.')\n",
    "#parser.add_argument('--camera', help='Camera devide number.', default=0, type=int)\n",
    "#args = parser.parse_args()\n",
    "\n",
    "VIDEO_URL = \"https://bl.webcaster.pro/media/playlist/free_361ac6c7ea479629f777e6fab966ead2_hd/381_81890575/1080p/74bd89dc811014cb7e81b42b51074713/4682340436.m3u8\"\n",
    "\n",
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "cap = cv2.VideoCapture(VIDEO_URL)\n",
    "\n",
    "#cap = cv.VideoCapture(args.camera)\n",
    "cv.namedWindow(window_capture_name)\n",
    "cv.namedWindow(window_detection_name)\n",
    "cv.createTrackbar(low_H_name, window_detection_name , low_H, max_value_H, on_low_H_thresh_trackbar)\n",
    "cv.createTrackbar(high_H_name, window_detection_name , high_H, max_value_H, on_high_H_thresh_trackbar)\n",
    "cv.createTrackbar(low_S_name, window_detection_name , low_S, max_value, on_low_S_thresh_trackbar)\n",
    "cv.createTrackbar(high_S_name, window_detection_name , high_S, max_value, on_high_S_thresh_trackbar)\n",
    "cv.createTrackbar(low_V_name, window_detection_name , low_V, max_value, on_low_V_thresh_trackbar)\n",
    "cv.createTrackbar(high_V_name, window_detection_name , high_V, max_value, on_high_V_thresh_trackbar)\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    frame_HSV = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "    frame_threshold = cv.inRange(frame_HSV, (low_H, low_S, low_V), (high_H, high_S, high_V))\n",
    "    \n",
    "    \n",
    "    cv.imshow(window_capture_name, frame)\n",
    "    cv.imshow(window_detection_name, frame_threshold)\n",
    "    \n",
    "    key = cv.waitKey(30)\n",
    "    if key == ord('q') or key == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    "img = cv2.imread('test2.png',cv2.IMREAD_COLOR)\n",
    "cv2.imshow('image',img)\n",
    "k = cv2.waitKey(0) & 0xFF\n",
    "if k == 27:         # wait for ESC key to exit\n",
    "     cv2.destroyAllWindows()\n",
    "elif k == ord('s'): # wait for 's' key to save and exit\n",
    "     cv2.imwrite('messigray.png',img)\n",
    "     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1679 * 1031\n",
      "(599, 567) * (1079, 807)\n",
      "0 0 0 * 180 255 255\n",
      "1679 * 1031\n",
      "(599, 567) * (1079, 807)\n",
      "0 0 0 * 180 255 255\n",
      "1679 * 1031\n",
      "(599, 567) * (1079, 807)\n",
      "0 0 0 * 180 255 255\n",
      "1679 * 1031\n",
      "(599, 567) * (1079, 807)\n",
      "0 0 0 * 180 255 255\n",
      "1679 * 1031\n",
      "(599, 567) * (1079, 807)\n",
      "0 0 0 * 180 255 255\n",
      "1679 * 1031\n",
      "(599, 567) * (1079, 807)\n",
      "0 0 0 * 180 255 255\n",
      "1679 * 1031\n",
      "(599, 567) * (1079, 807)\n",
      "0 0 0 * 180 255 255\n",
      "1679 * 1031\n",
      "(599, 567) * (1079, 807)\n",
      "0 0 0 * 180 255 255\n",
      "1679 * 1031\n",
      "(599, 567) * (1079, 807)\n",
      "0 0 0 * 180 255 255\n",
      "1679 * 1031\n",
      "(599, 567) * (1079, 807)\n",
      "0 0 0 * 180 255 255\n",
      "1679 * 1031\n",
      "(599, 567) * (1079, 807)\n",
      "0 0 0 * 180 255 255\n",
      "1679 * 1031\n",
      "(599, 567) * (1079, 807)\n",
      "0 0 0 * 180 255 255\n",
      "1679 * 1031\n",
      "(599, 567) * (1079, 807)\n",
      "0 0 0 * 180 255 255\n",
      "1679 * 1031\n",
      "(599, 567) * (1079, 807)\n",
      "0 0 0 * 180 255 255\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "window_name = \"Crop\"\n",
    "max_value = 255\n",
    "max_value_H = 360//2\n",
    "#max_value_H = 360\n",
    "\n",
    "low_H = 0\n",
    "low_S = 0\n",
    "low_V = 0\n",
    "high_H = max_value_H\n",
    "high_S = max_value\n",
    "high_V = max_value\n",
    "\n",
    "low_H_name = 'Low H'\n",
    "low_S_name = 'Low S'\n",
    "low_V_name = 'Low V'\n",
    "high_H_name = 'High H'\n",
    "high_S_name = 'High S'\n",
    "high_V_name = 'High V'\n",
    "\n",
    "def on_low_H_thresh_trackbar(val):\n",
    "    global low_H\n",
    "    global high_H\n",
    "    low_H = val\n",
    "    low_H = min(high_H-1, low_H)\n",
    "    cv2.setTrackbarPos(low_H_name, window_name, low_H)\n",
    "def on_high_H_thresh_trackbar(val):\n",
    "    global low_H\n",
    "    global high_H\n",
    "    high_H = val\n",
    "    high_H = max(high_H, low_H+1)\n",
    "    cv2.setTrackbarPos(high_H_name, window_name, high_H)\n",
    "def on_low_S_thresh_trackbar(val):\n",
    "    global low_S\n",
    "    global high_S\n",
    "    low_S = val\n",
    "    low_S = min(high_S-1, low_S)\n",
    "    cv2.setTrackbarPos(low_S_name, window_name, low_S)\n",
    "def on_high_S_thresh_trackbar(val):\n",
    "    global low_S\n",
    "    global high_S\n",
    "    high_S = val\n",
    "    high_S = max(high_S, low_S+1)\n",
    "    cv2.setTrackbarPos(high_S_name, window_name, high_S)\n",
    "def on_low_V_thresh_trackbar(val):\n",
    "    global low_V\n",
    "    global high_V\n",
    "    low_V = val\n",
    "    low_V = min(high_V-1, low_V)\n",
    "    cv2.setTrackbarPos(low_V_name, window_name, low_V)\n",
    "def on_high_V_thresh_trackbar(val):\n",
    "    global low_V\n",
    "    global high_V\n",
    "    high_V = val\n",
    "    high_V = max(high_V, low_V+1)\n",
    "    cv2.setTrackbarPos(high_V_name, window_name, high_V)\n",
    "    \n",
    "def createTrackBar(window_name):\n",
    "    cv2.createTrackbar(low_H_name, window_name , low_H, max_value_H, on_low_H_thresh_trackbar)\n",
    "    cv2.createTrackbar(high_H_name, window_name , high_H, max_value_H, on_high_H_thresh_trackbar)\n",
    "    cv2.createTrackbar(low_S_name, window_name , low_S, max_value, on_low_S_thresh_trackbar)\n",
    "    cv2.createTrackbar(high_S_name, window_name , high_S, max_value, on_high_S_thresh_trackbar)\n",
    "    cv2.createTrackbar(low_V_name, window_name , low_V, max_value, on_low_V_thresh_trackbar)\n",
    "    cv2.createTrackbar(high_V_name, window_name , high_V, max_value, on_high_V_thresh_trackbar)\n",
    "w,h = 480,240\n",
    "# Read until video is completed\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    frame = cv2.imread('test2.png',cv2.IMREAD_COLOR)\n",
    "\n",
    "#frameWIDTH  = frame.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "#frameHEIGHT = frame.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    frameHEIGHT,frameWIDTH = frame.shape[:2]\n",
    "\n",
    "    abox = (int(w),int(h))\n",
    "    bbox = (frameWIDTH/2-abox[0]/2, frameHEIGHT*2/3-abox[1]/2,abox[0], abox[1])\n",
    "\n",
    "    # Draw bounding box\n",
    "    p1 = (int(bbox[0]), int(bbox[1]))\n",
    "    p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "\n",
    "    print(frameWIDTH,\"*\",frameHEIGHT)\n",
    "    print(p1,\"*\",p2)\n",
    "\n",
    "    crop_img = frame[p1[1]:p2[1],p1[0]:p2[0]]\n",
    "       \n",
    "    frame_HSV = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)\n",
    "    #frame_HSV = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HLS)\n",
    "    frame_threshold = cv2.inRange(frame_HSV, (low_H, low_S, low_V), (high_H, high_S, high_V))\n",
    " \n",
    "    print(low_H, low_S, low_V,\"*\",high_H, high_S, high_V)\n",
    "    \n",
    "    cv2.imshow('Crop',frame_threshold)        \n",
    "    createTrackBar('Crop')\n",
    "        \n",
    "    # Draw bounding box\n",
    "    cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "    cv2.imshow('Frame',frame)\n",
    "\n",
    "#if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        # Closes all the frames\n",
    "#        cv2.destroyAllWindows()\n",
    "    k = cv2.waitKey(0) & 0xFF\n",
    "    if k == 27:         # wait for ESC key to exit\n",
    "         cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "White = Saturation(0..20) AND Value(230..255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c simonflueckiger tesserocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Google Drive\\\\Coursera\\\\Play2Live'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1679 * 1031\n",
      "(599, 567) * (1079, 807)\n",
      "Text:  :- ' :Z-[ZIM/ﬂ/Il'fﬂ Fm\n",
      "\n",
      "ENEMY TRAPPED- 25 ‘\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd ='C:\\\\Program Files (x86)\\\\Tesseract-OCR\\\\tesseract'\n",
    "tessdata_dir_config = '--tessdata-dir \"C:\\\\Program Files (x86)\\\\Tesseract-OCR\\\\tessdata\"'\n",
    "\n",
    "def extractText(frame):\n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Red lower mask (0-10)\n",
    "    lower_red = np.array([0,70,50])\n",
    "#    lower_red = np.array([0,50,50])\n",
    "    upper_red = np.array([10,255,255])\n",
    "    mask_r0 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "    # Red upper mask (170-180)\n",
    "    lower_red = np.array([170,70,50])\n",
    "#    lower_red = np.array([170,50,50])\n",
    "    upper_red = np.array([180,255,255])\n",
    "    mask_r1 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "\n",
    "    # define range of white color in HSV\n",
    "    lower_white = np.array([0,0,230])\n",
    "    upper_white = np.array([180,20,255])\n",
    "    mask_w = cv2.inRange(hsv, lower_white, upper_white)\n",
    "\n",
    "#    mask = mask_w\n",
    "    mask = mask_r0|mask_r1|mask_w\n",
    "\n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "#    res =  mask\n",
    "\n",
    "    return res\n",
    "\n",
    "w,h = 480,240\n",
    "# Capture frame-by-frame\n",
    "frame = cv2.imread('test2.png',cv2.IMREAD_COLOR)\n",
    "\n",
    "#frameWIDTH  = frame.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "#frameHEIGHT = frame.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "frameHEIGHT,frameWIDTH = frame.shape[:2]\n",
    "\n",
    "abox = (int(w),int(h))\n",
    "bbox = (frameWIDTH/2-abox[0]/2, frameHEIGHT*2/3-abox[1]/2,abox[0], abox[1])\n",
    "\n",
    "# Draw bounding box\n",
    "p1 = (int(bbox[0]), int(bbox[1]))\n",
    "p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "\n",
    "print(frameWIDTH,\"*\",frameHEIGHT)\n",
    "print(p1,\"*\",p2)\n",
    "\n",
    "crop_img = frame[p1[1]:p2[1],p1[0]:p2[0]]\n",
    "#im = Image.open(\"sample1.jpg\")\n",
    "#img = Image.open(\"test2.png\")\n",
    "#print(img.height,img.width)\n",
    "#area = (600, 600, 1200, 800)\n",
    "#crop_img = img.crop(area)\n",
    "#crop_img.show()\n",
    "\n",
    "img = extractText(crop_img)\n",
    "\n",
    "# Convert it into grayscale and display again\n",
    "bgr = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    \n",
    "cv2.imshow('Crop',gray)        \n",
    "\n",
    "text = pytesseract.image_to_string(Image.fromarray(gray))\n",
    "#text = pytesseract.image_to_string(cropped_img, lang = 'eng')\n",
    "\n",
    "print(\"Text: \",text)\n",
    "k = cv2.waitKey(0) & 0xFF\n",
    "if k == 27:         # wait for ESC key to exit\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

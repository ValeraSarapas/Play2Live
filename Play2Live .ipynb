{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook requred installed tesseract engine. Instruction about installation of the engine i here:\n",
    "https://github.com/tesseract-ocr/tesseract\n",
    "\n",
    "To start: Run All\n",
    "To exit: press \"Q\"\n",
    "Main window contains wideo streem. \"Crop\" windows dislay filters work.\n",
    "Recognised ivent shown on main windows after red \"Text:\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setAnalisisArea(w,h):\n",
    "    streamWIDTH  = stream.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    streamHEIGHT = stream.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "\n",
    "    # Define an initial bounding box\n",
    "    abox = (int(w),int(h))\n",
    "    bbox = (streamWIDTH/2-abox[0]/2, streamHEIGHT*2/3-abox[1]/2,abox[0], abox[1])\n",
    "    \n",
    "    # Draw bounding box\n",
    "    p1 = (int(bbox[0]), int(bbox[1]))\n",
    "    p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "    return p1,p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawInfoBox(frame,p1,p2,text,ocr_text):\n",
    "    \n",
    "    # Check screen parameters\n",
    "    streamFPS = stream.get(cv2.CAP_PROP_FPS)\n",
    "    streamWIDTH  = stream.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    streamHEIGHT = stream.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "    # Draw bounding box\n",
    "    cv2.rectangle(frame, p1, p2, (255,0,0), 2, 1)\n",
    "\n",
    "\n",
    "    # Display text on frame\n",
    "    cv2.putText(frame,\"Info: \", (p2[0]+10,p1[1] - 10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255,0,0),2);  \n",
    "    cv2.putText(frame,\"OCR:    \"+ocr_text, (p2[0]+10,p1[1] + 40), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255,0,0),2);  \n",
    "\n",
    "#    cv2.putText(frame,\"FPS:    \"+str(streamFPS), (p2[0]+10,p1[1] + 15), \n",
    "#                cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255,0,0),2);  \n",
    "#    cv2.putText(frame,\"Width:  \"+str(streamWIDTH), (p2[0]+10,p1[1] + 40), \n",
    "#                cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255,0,0),2);  \n",
    "#    cv2.putText(frame,\"Height: \"+str(streamHEIGHT), (p2[0]+10,p1[1] + 65), \n",
    "#                cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255,0,0),2);  \n",
    "    cv2.putText(frame,\"Text: \"+ text, (p2[0]+10,p1[1] + 90), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,255),2);  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractText(frame):\n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "    # Red lower mask (0-10)\n",
    "    lower_red = np.array([0,70,50])\n",
    "#    lower_red = np.array([0,50,50])\n",
    "    upper_red = np.array([10,255,255])\n",
    "    mask_r0 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "    # Red upper mask (170-180)\n",
    "    lower_red = np.array([170,70,50])\n",
    "#    lower_red = np.array([170,50,50])\n",
    "    upper_red = np.array([180,255,255])\n",
    "    mask_r1 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "\n",
    "    # define range of white color in HSV\n",
    "    lower_white = np.array([0,0,230])\n",
    "    upper_white = np.array([180,20,255])\n",
    "    mask_w = cv2.inRange(hsv, lower_white, upper_white)\n",
    "\n",
    "    # join my masks\n",
    "#    mask_2 = cv2.inRange(frame, (low_H, low_S, low_V), (high_H, high_S, high_V))\n",
    "    \n",
    "#    mask = mask +mask0+mask1\n",
    "#    mask = mask + mask1\n",
    "#    mask = cv2.bitwise_xor(mask1, mask)\n",
    "#    mask = mask_r0|mask_r1|mask_w\n",
    "    mask = mask_w\n",
    "\n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    " \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_URL = \"https://bl.webcaster.pro/media/playlist/free_361ac6c7ea479629f777e6fab966ead2_hd/381_81890575/1080p/74bd89dc811014cb7e81b42b51074713/4682340436.m3u8\"\n",
    "\n",
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "stream = cv2.VideoCapture(VIDEO_URL)\n",
    "\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (stream.isOpened()== False): \n",
    "    print(\"Error opening video stream or file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b8c5795e2760>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# OR explicit beforehand converting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mocr_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;31m#        print(pytesseract.image_to_string(Image.fromarray(gray))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m#        print(ocr_text)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\Lib\\site-packages\\pytesseract\\pytesseract.py\u001b[0m in \u001b[0;36mimage_to_string\u001b[1;34m(image, lang, config, nice, boxes, output_type)\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\Lib\\site-packages\\pytesseract\\pytesseract.py\u001b[0m in \u001b[0;36mrun_and_get_output\u001b[1;34m(image, extension, lang, config, nice, return_bytes)\u001b[0m\n\u001b[0;32m    192\u001b[0m         }\n\u001b[0;32m    193\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mrun_tesseract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'output_filename_base'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextsep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\Lib\\site-packages\\pytesseract\\pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[1;34m(input_filename, output_filename_base, extension, lang, config, nice)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msubprocess_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[0mstatus_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m     \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout, endtime)\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m                 result = _winapi.WaitForSingleObject(self._handle,\n\u001b[1;32m-> 1055\u001b[1;33m                                                     timeout_millis)\n\u001b[0m\u001b[0;32m   1056\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_winapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWAIT_TIMEOUT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutExpired\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd ='C:\\\\Program Files (x86)\\\\Tesseract-OCR\\\\tesseract'\n",
    "tessdata_dir_config = '--tessdata-dir \"C:\\\\Program Files (x86)\\\\Tesseract-OCR\\\\tessdata\"'\n",
    "\n",
    "w,h = 480,240\n",
    "# Read until video is completed\n",
    "while(stream.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = stream.read()\n",
    "    if ret == True:\n",
    "        p1,p2 = setAnalisisArea(w,h)\n",
    "        \n",
    "        crop_img = frame[p1[1]:p2[1],p1[0]:p2[0]]\n",
    "        \n",
    "        img = extractText(crop_img)\n",
    "\n",
    "#        cv2.imshow('Crop',img)        \n",
    "#        createTrackBar('Crop')\n",
    "        # Convert it into grayscale and display again\n",
    "        bgr = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "        gray = cv2.bitwise_not(gray)\n",
    "        \n",
    "        # Apply dilation and erosion to remove some noise\n",
    "        kernel = np.ones((1, 1), np.uint8)\n",
    "        gray = cv2.dilate(gray, kernel, iterations=1)\n",
    "        gray = cv2.erode(gray, kernel, iterations=1)\n",
    "\n",
    "        cv2.imshow('Crop',gray)        \n",
    "        \n",
    "        # Smooth the image to get more accurate results\n",
    "        # Define the kernel size for gaussian smoothing\n",
    "#        kernel_size = 5\n",
    "#        blur_gray = cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "#        cv2.imshow('Crop', blur_gray) \n",
    "\n",
    "#        filename = \"{}.png\".format(os.getpid())\n",
    "#        cv2.imwrite(filename, gray)\n",
    "#        text = pytesseract.image_to_string(Image.open(filename))\n",
    "#        os.remove(filename)\n",
    "        \n",
    "        # OR explicit beforehand converting\n",
    "        ocr_text = pytesseract.image_to_string(Image.fromarray(gray))\n",
    "#        print(pytesseract.image_to_string(Image.fromarray(gray))\n",
    "#        print(ocr_text)\n",
    "#        low_threshold = 100\n",
    "#        high_threshold = 200\n",
    "#        edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "#        cv2.imshow('Crop', edges) \n",
    "\n",
    "        if \"eliminated\" in ocr_text.lower():\n",
    "            text = \"Eliminated event detected\"\n",
    "        elif \"asist\" in ocr_text.lower():\n",
    "            text = \"Asist event detected\"\n",
    "        elif \"objective defense\" in ocr_text.lower():\n",
    "            text = \"Objective defense event detected\"\n",
    "        elif \"enemy trapped\" in ocr_text.lower():\n",
    "            text = \"Enemy trapped event detected\"\n",
    "        else:\n",
    "            text=\"\"\n",
    "            \n",
    "        drawInfoBox(frame,p1,p2,text,ocr_text)    \n",
    "        cv2.imshow('Frame',frame)\n",
    "        \n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    " \n",
    "    # Break the loop\n",
    "    else: \n",
    "            break\n",
    "\n",
    "# When everything done, release the video capture object\n",
    "stream.release()\n",
    " \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
